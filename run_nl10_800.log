Loading pretrained model
Loading datasets
Training
Loading fine-tuned weights from adapters/mindmate_llama32_3b_lora/0000600_adapters.safetensors
Trainable parameters: 0.135% (4.342M/3212.750M)
Starting training..., iters: 800
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:01<00:24,  1.03s/it]Calculating loss...:   8%|▊         | 2/25 [00:02<00:32,  1.41s/it]Calculating loss...:  12%|█▏        | 3/25 [00:03<00:25,  1.14s/it]Calculating loss...:  16%|█▌        | 4/25 [00:04<00:23,  1.13s/it]Calculating loss...:  20%|██        | 5/25 [00:05<00:19,  1.03it/s]Calculating loss...:  24%|██▍       | 6/25 [00:06<00:20,  1.06s/it]Calculating loss...:  28%|██▊       | 7/25 [00:09<00:28,  1.59s/it]Calculating loss...:  32%|███▏      | 8/25 [00:10<00:26,  1.58s/it]Calculating loss...:  36%|███▌      | 9/25 [00:11<00:19,  1.22s/it]Calculating loss...:  40%|████      | 10/25 [00:12<00:18,  1.23s/it]Calculating loss...:  44%|████▍     | 11/25 [00:14<00:20,  1.43s/it]Calculating loss...:  48%|████▊     | 12/25 [00:16<00:19,  1.52s/it]Calculating loss...:  52%|█████▏    | 13/25 [00:16<00:14,  1.24s/it]Calculating loss...:  56%|█████▌    | 14/25 [00:17<00:11,  1.08s/it]Calculating loss...:  60%|██████    | 15/25 [00:17<00:08,  1.14it/s]Calculating loss...:  64%|██████▍   | 16/25 [00:18<00:07,  1.21it/s]Calculating loss...:  68%|██████▊   | 17/25 [00:21<00:11,  1.47s/it]Calculating loss...:  72%|███████▏  | 18/25 [00:22<00:10,  1.45s/it]Calculating loss...:  76%|███████▌  | 19/25 [00:24<00:09,  1.53s/it]Calculating loss...:  80%|████████  | 20/25 [00:25<00:06,  1.28s/it]Calculating loss...:  84%|████████▍ | 21/25 [00:27<00:06,  1.66s/it]Calculating loss...:  88%|████████▊ | 22/25 [00:28<00:03,  1.33s/it]Calculating loss...:  92%|█████████▏| 23/25 [00:29<00:02,  1.31s/it]Calculating loss...:  96%|█████████▌| 24/25 [00:30<00:01,  1.09s/it]Calculating loss...: 100%|██████████| 25/25 [00:32<00:00,  1.36s/it]Calculating loss...: 100%|██████████| 25/25 [00:32<00:00,  1.29s/it]
Iter 1: Val loss 2.260, Val took 32.260s
Iter 50: Train loss 2.282, Learning Rate 7.000e-05, It/sec 0.467, Tokens/sec 219.836, Trained Tokens 23525, Peak mem 8.488 GB
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:02<00:59,  2.47s/it]Calculating loss...:   8%|▊         | 2/25 [00:02<00:30,  1.32s/it]Calculating loss...:  12%|█▏        | 3/25 [00:03<00:22,  1.03s/it]Calculating loss...:  16%|█▌        | 4/25 [00:05<00:31,  1.49s/it]Calculating loss...:  20%|██        | 5/25 [00:06<00:26,  1.33s/it]Calculating loss...:  24%|██▍       | 6/25 [00:07<00:21,  1.13s/it]Calculating loss...:  28%|██▊       | 7/25 [00:09<00:22,  1.27s/it]Calculating loss...:  32%|███▏      | 8/25 [00:09<00:18,  1.09s/it]Calculating loss...:  36%|███▌      | 9/25 [00:10<00:14,  1.09it/s]Calculating loss...:  40%|████      | 10/25 [00:10<00:11,  1.26it/s]Calculating loss...:  44%|████▍     | 11/25 [00:11<00:10,  1.40it/s]Calculating loss...:  48%|████▊     | 12/25 [00:11<00:07,  1.65it/s]Calculating loss...:  52%|█████▏    | 13/25 [00:13<00:11,  1.08it/s]Calculating loss...:  56%|█████▌    | 14/25 [00:15<00:13,  1.23s/it]Calculating loss...:  60%|██████    | 15/25 [00:17<00:13,  1.38s/it]Calculating loss...:  64%|██████▍   | 16/25 [00:19<00:13,  1.56s/it]Calculating loss...:  68%|██████▊   | 17/25 [00:22<00:16,  2.06s/it]Calculating loss...:  72%|███████▏  | 18/25 [00:24<00:15,  2.19s/it]Calculating loss...:  76%|███████▌  | 19/25 [00:26<00:12,  2.06s/it]Calculating loss...:  80%|████████  | 20/25 [00:28<00:10,  2.14s/it]Calculating loss...:  84%|████████▍ | 21/25 [00:31<00:08,  2.20s/it]Calculating loss...:  88%|████████▊ | 22/25 [00:32<00:06,  2.01s/it]Calculating loss...:  92%|█████████▏| 23/25 [00:36<00:04,  2.48s/it]Calculating loss...:  96%|█████████▌| 24/25 [00:37<00:02,  2.10s/it]Calculating loss...: 100%|██████████| 25/25 [00:41<00:00,  2.66s/it]Calculating loss...: 100%|██████████| 25/25 [00:41<00:00,  1.67s/it]
Iter 100: Val loss 2.376, Val took 41.632s
Iter 100: Train loss 2.190, Learning Rate 7.000e-05, It/sec 0.384, Tokens/sec 177.144, Trained Tokens 46618, Peak mem 8.488 GB
Iter 100: Saved adapter weights to adapters/mindmate_llama32_3b_lora/adapters.safetensors and adapters/mindmate_llama32_3b_lora/0000100_adapters.safetensors.
Iter 150: Train loss 2.146, Learning Rate 7.000e-05, It/sec 0.388, Tokens/sec 187.348, Trained Tokens 70777, Peak mem 8.559 GB
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:02<00:53,  2.21s/it]Calculating loss...:   8%|▊         | 2/25 [00:04<00:47,  2.08s/it]Calculating loss...:  12%|█▏        | 3/25 [00:07<00:54,  2.48s/it]Calculating loss...:  16%|█▌        | 4/25 [00:08<00:38,  1.84s/it]Calculating loss...:  20%|██        | 5/25 [00:09<00:33,  1.70s/it]Calculating loss...:  24%|██▍       | 6/25 [00:09<00:24,  1.30s/it]Calculating loss...:  28%|██▊       | 7/25 [00:10<00:19,  1.11s/it]Calculating loss...:  32%|███▏      | 8/25 [00:12<00:21,  1.27s/it]Calculating loss...:  36%|███▌      | 9/25 [00:14<00:23,  1.45s/it]Calculating loss...:  40%|████      | 10/25 [00:15<00:23,  1.55s/it]Calculating loss...:  44%|████▍     | 11/25 [00:16<00:17,  1.24s/it]Calculating loss...:  48%|████▊     | 12/25 [00:17<00:14,  1.08s/it]Calculating loss...:  52%|█████▏    | 13/25 [00:17<00:10,  1.09it/s]Calculating loss...:  56%|█████▌    | 14/25 [00:18<00:11,  1.02s/it]Calculating loss...:  60%|██████    | 15/25 [00:19<00:08,  1.14it/s]Calculating loss...:  64%|██████▍   | 16/25 [00:22<00:12,  1.39s/it]Calculating loss...:  68%|██████▊   | 17/25 [00:23<00:10,  1.34s/it]Calculating loss...:  72%|███████▏  | 18/25 [00:25<00:11,  1.65s/it]Calculating loss...:  76%|███████▌  | 19/25 [00:27<00:10,  1.82s/it]Calculating loss...:  80%|████████  | 20/25 [00:30<00:09,  1.92s/it]Calculating loss...:  84%|████████▍ | 21/25 [00:30<00:06,  1.61s/it]Calculating loss...:  88%|████████▊ | 22/25 [00:32<00:05,  1.67s/it]Calculating loss...:  92%|█████████▏| 23/25 [00:35<00:03,  1.84s/it]Calculating loss...:  96%|█████████▌| 24/25 [00:35<00:01,  1.44s/it]Calculating loss...: 100%|██████████| 25/25 [00:36<00:00,  1.28s/it]Calculating loss...: 100%|██████████| 25/25 [00:36<00:00,  1.46s/it]
Iter 200: Val loss 2.213, Val took 36.431s
Iter 200: Train loss 2.175, Learning Rate 7.000e-05, It/sec 0.421, Tokens/sec 186.503, Trained Tokens 92927, Peak mem 8.559 GB
Iter 200: Saved adapter weights to adapters/mindmate_llama32_3b_lora/adapters.safetensors and adapters/mindmate_llama32_3b_lora/0000200_adapters.safetensors.
Iter 250: Train loss 2.087, Learning Rate 7.000e-05, It/sec 0.377, Tokens/sec 180.293, Trained Tokens 116839, Peak mem 8.559 GB
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:00<00:21,  1.10it/s]Calculating loss...:   8%|▊         | 2/25 [00:01<00:16,  1.40it/s]Calculating loss...:  12%|█▏        | 3/25 [00:03<00:29,  1.34s/it]Calculating loss...:  16%|█▌        | 4/25 [00:05<00:31,  1.48s/it]Calculating loss...:  20%|██        | 5/25 [00:07<00:33,  1.68s/it]Calculating loss...:  24%|██▍       | 6/25 [00:07<00:24,  1.31s/it]Calculating loss...:  28%|██▊       | 7/25 [00:08<00:19,  1.11s/it]Calculating loss...:  32%|███▏      | 8/25 [00:10<00:24,  1.47s/it]Calculating loss...:  36%|███▌      | 9/25 [00:12<00:23,  1.47s/it]Calculating loss...:  40%|████      | 10/25 [00:14<00:26,  1.78s/it]Calculating loss...:  44%|████▍     | 11/25 [00:16<00:23,  1.68s/it]Calculating loss...:  48%|████▊     | 12/25 [00:18<00:24,  1.85s/it]Calculating loss...:  52%|█████▏    | 13/25 [00:22<00:31,  2.64s/it]Calculating loss...:  56%|█████▌    | 14/25 [00:24<00:25,  2.30s/it]Calculating loss...:  60%|██████    | 15/25 [00:27<00:24,  2.47s/it]Calculating loss...:  64%|██████▍   | 16/25 [00:30<00:23,  2.61s/it]Calculating loss...:  68%|██████▊   | 17/25 [00:31<00:16,  2.11s/it]Calculating loss...:  72%|███████▏  | 18/25 [00:33<00:14,  2.11s/it]Calculating loss...:  76%|███████▌  | 19/25 [00:35<00:13,  2.20s/it]Calculating loss...:  80%|████████  | 20/25 [00:36<00:08,  1.65s/it]Calculating loss...:  84%|████████▍ | 21/25 [00:36<00:05,  1.43s/it]Calculating loss...:  88%|████████▊ | 22/25 [00:39<00:05,  1.87s/it]Calculating loss...:  92%|█████████▏| 23/25 [00:41<00:03,  1.81s/it]Calculating loss...:  96%|█████████▌| 24/25 [00:43<00:01,  1.90s/it]Calculating loss...: 100%|██████████| 25/25 [00:46<00:00,  2.08s/it]Calculating loss...: 100%|██████████| 25/25 [00:46<00:00,  1.85s/it]
Iter 300: Val loss 2.139, Val took 46.163s
Iter 300: Train loss 2.109, Learning Rate 7.000e-05, It/sec 0.430, Tokens/sec 177.668, Trained Tokens 137482, Peak mem 8.875 GB
Iter 300: Saved adapter weights to adapters/mindmate_llama32_3b_lora/adapters.safetensors and adapters/mindmate_llama32_3b_lora/0000300_adapters.safetensors.
Iter 350: Train loss 2.162, Learning Rate 7.000e-05, It/sec 0.358, Tokens/sec 155.467, Trained Tokens 159225, Peak mem 8.875 GB
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:02<01:08,  2.86s/it]Calculating loss...:   8%|▊         | 2/25 [00:03<00:39,  1.74s/it]Calculating loss...:  12%|█▏        | 3/25 [00:05<00:34,  1.56s/it]Calculating loss...:  16%|█▌        | 4/25 [00:05<00:24,  1.18s/it]Calculating loss...:  20%|██        | 5/25 [00:06<00:20,  1.03s/it]Calculating loss...:  24%|██▍       | 6/25 [00:07<00:20,  1.07s/it]Calculating loss...:  28%|██▊       | 7/25 [00:09<00:20,  1.16s/it]Calculating loss...:  32%|███▏      | 8/25 [00:09<00:17,  1.04s/it]Calculating loss...:  36%|███▌      | 9/25 [00:13<00:31,  2.00s/it]Calculating loss...:  40%|████      | 10/25 [00:16<00:34,  2.30s/it]Calculating loss...:  44%|████▍     | 11/25 [00:18<00:30,  2.18s/it]Calculating loss...:  48%|████▊     | 12/25 [00:19<00:22,  1.75s/it]Calculating loss...:  52%|█████▏    | 13/25 [00:22<00:23,  1.99s/it]Calculating loss...:  56%|█████▌    | 14/25 [00:22<00:17,  1.56s/it]Calculating loss...:  60%|██████    | 15/25 [00:24<00:16,  1.69s/it]Calculating loss...:  64%|██████▍   | 16/25 [00:26<00:16,  1.87s/it]Calculating loss...:  68%|██████▊   | 17/25 [00:28<00:14,  1.76s/it]Calculating loss...:  72%|███████▏  | 18/25 [00:29<00:09,  1.41s/it]Calculating loss...:  76%|███████▌  | 19/25 [00:31<00:10,  1.69s/it]Calculating loss...:  80%|████████  | 20/25 [00:33<00:09,  1.89s/it]Calculating loss...:  84%|████████▍ | 21/25 [00:35<00:07,  1.90s/it]Calculating loss...:  88%|████████▊ | 22/25 [00:38<00:06,  2.09s/it]Calculating loss...:  92%|█████████▏| 23/25 [00:38<00:03,  1.70s/it]Calculating loss...:  96%|█████████▌| 24/25 [00:40<00:01,  1.54s/it]Calculating loss...: 100%|██████████| 25/25 [00:40<00:00,  1.25s/it]Calculating loss...: 100%|██████████| 25/25 [00:40<00:00,  1.63s/it]
Iter 400: Val loss 2.230, Val took 40.761s
Iter 400: Train loss 2.163, Learning Rate 7.000e-05, It/sec 0.333, Tokens/sec 171.299, Trained Tokens 184976, Peak mem 8.928 GB
Iter 400: Saved adapter weights to adapters/mindmate_llama32_3b_lora/adapters.safetensors and adapters/mindmate_llama32_3b_lora/0000400_adapters.safetensors.
Iter 450: Train loss 1.967, Learning Rate 7.000e-05, It/sec 0.361, Tokens/sec 166.856, Trained Tokens 208090, Peak mem 8.928 GB
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:00<00:23,  1.01it/s]Calculating loss...:   8%|▊         | 2/25 [00:03<00:38,  1.69s/it]Calculating loss...:  12%|█▏        | 3/25 [00:05<00:44,  2.03s/it]Calculating loss...:  16%|█▌        | 4/25 [00:07<00:43,  2.07s/it]Calculating loss...:  20%|██        | 5/25 [00:10<00:43,  2.18s/it]Calculating loss...:  24%|██▍       | 6/25 [00:10<00:31,  1.64s/it]Calculating loss...:  28%|██▊       | 7/25 [00:12<00:29,  1.62s/it]Calculating loss...:  32%|███▏      | 8/25 [00:13<00:23,  1.36s/it]Calculating loss...:  36%|███▌      | 9/25 [00:15<00:27,  1.75s/it]Calculating loss...:  40%|████      | 10/25 [00:18<00:29,  1.95s/it]Calculating loss...:  44%|████▍     | 11/25 [00:18<00:21,  1.54s/it]Calculating loss...:  48%|████▊     | 12/25 [00:19<00:17,  1.36s/it]Calculating loss...:  52%|█████▏    | 13/25 [00:20<00:15,  1.31s/it]Calculating loss...:  56%|█████▌    | 14/25 [00:21<00:12,  1.15s/it]Calculating loss...:  60%|██████    | 15/25 [00:22<00:10,  1.10s/it]Calculating loss...:  64%|██████▍   | 16/25 [00:23<00:09,  1.01s/it]Calculating loss...:  68%|██████▊   | 17/25 [00:25<00:11,  1.41s/it]Calculating loss...:  72%|███████▏  | 18/25 [00:27<00:11,  1.64s/it]Calculating loss...:  76%|███████▌  | 19/25 [00:29<00:09,  1.63s/it]Calculating loss...:  80%|████████  | 20/25 [00:33<00:11,  2.23s/it]Calculating loss...:  84%|████████▍ | 21/25 [00:33<00:06,  1.74s/it]Calculating loss...:  88%|████████▊ | 22/25 [00:35<00:05,  1.80s/it]Calculating loss...:  92%|█████████▏| 23/25 [00:38<00:04,  2.17s/it]Calculating loss...:  96%|█████████▌| 24/25 [00:41<00:02,  2.21s/it]Calculating loss...: 100%|██████████| 25/25 [00:42<00:00,  2.02s/it]Calculating loss...: 100%|██████████| 25/25 [00:42<00:00,  1.70s/it]
Iter 500: Val loss 2.231, Val took 42.607s
Iter 500: Train loss 2.053, Learning Rate 7.000e-05, It/sec 0.412, Tokens/sec 165.511, Trained Tokens 228174, Peak mem 8.928 GB
Iter 500: Saved adapter weights to adapters/mindmate_llama32_3b_lora/adapters.safetensors and adapters/mindmate_llama32_3b_lora/0000500_adapters.safetensors.
Iter 550: Train loss 2.042, Learning Rate 7.000e-05, It/sec 0.366, Tokens/sec 148.768, Trained Tokens 248471, Peak mem 8.928 GB
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:02<01:04,  2.69s/it]Calculating loss...:   8%|▊         | 2/25 [00:05<01:09,  3.03s/it]Calculating loss...:  12%|█▏        | 3/25 [00:06<00:46,  2.10s/it]Calculating loss...:  16%|█▌        | 4/25 [00:07<00:32,  1.54s/it]Calculating loss...:  20%|██        | 5/25 [00:10<00:41,  2.08s/it]Calculating loss...:  24%|██▍       | 6/25 [00:11<00:30,  1.62s/it]Calculating loss...:  28%|██▊       | 7/25 [00:14<00:35,  1.96s/it]Calculating loss...:  32%|███▏      | 8/25 [00:14<00:24,  1.46s/it]Calculating loss...:  36%|███▌      | 9/25 [00:16<00:24,  1.53s/it]Calculating loss...:  40%|████      | 10/25 [00:17<00:21,  1.42s/it]Calculating loss...:  44%|████▍     | 11/25 [00:17<00:16,  1.16s/it]Calculating loss...:  48%|████▊     | 12/25 [00:19<00:15,  1.16s/it]Calculating loss...:  52%|█████▏    | 13/25 [00:20<00:14,  1.22s/it]Calculating loss...:  56%|█████▌    | 14/25 [00:20<00:11,  1.03s/it]Calculating loss...:  60%|██████    | 15/25 [00:22<00:13,  1.31s/it]Calculating loss...:  64%|██████▍   | 16/25 [00:23<00:10,  1.15s/it]Calculating loss...:  68%|██████▊   | 17/25 [00:24<00:09,  1.15s/it]Calculating loss...:  72%|███████▏  | 18/25 [00:26<00:09,  1.39s/it]Calculating loss...:  76%|███████▌  | 19/25 [00:28<00:09,  1.57s/it]Calculating loss...:  80%|████████  | 20/25 [00:29<00:06,  1.27s/it]Calculating loss...:  84%|████████▍ | 21/25 [00:30<00:05,  1.37s/it]Calculating loss...:  88%|████████▊ | 22/25 [00:33<00:04,  1.57s/it]Calculating loss...:  92%|█████████▏| 23/25 [00:34<00:03,  1.63s/it]Calculating loss...:  96%|█████████▌| 24/25 [00:35<00:01,  1.27s/it]Calculating loss...: 100%|██████████| 25/25 [00:36<00:00,  1.39s/it]Calculating loss...: 100%|██████████| 25/25 [00:36<00:00,  1.48s/it]
Iter 600: Val loss 2.250, Val took 36.907s
Iter 600: Train loss 2.115, Learning Rate 7.000e-05, It/sec 0.472, Tokens/sec 218.112, Trained Tokens 271594, Peak mem 8.928 GB
Iter 600: Saved adapter weights to adapters/mindmate_llama32_3b_lora/adapters.safetensors and adapters/mindmate_llama32_3b_lora/0000600_adapters.safetensors.
Iter 650: Train loss 2.176, Learning Rate 7.000e-05, It/sec 0.402, Tokens/sec 165.047, Trained Tokens 292146, Peak mem 8.928 GB
