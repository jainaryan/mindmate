{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix_mindmate_text_jsonl.py\n",
    "import json, re, sys\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "IN = sys.argv[1]          # e.g., train.jsonl\n",
    "OUT = sys.argv[2]         # e.g., train.fixed.jsonl\n",
    "MODEL_DIR = sys.argv[3]   # tokenizer dir (same as model)\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=True)\n",
    "EOS = tok.eos_token or \"</s>\"\n",
    "\n",
    "def split_turns(text: str):\n",
    "    # Keep the role tags in the result list\n",
    "    parts = re.split(r'(<\\|user\\|>|<\\|assistant\\|>)', text)\n",
    "    # parts like [\"\", \"<|user|>\", \" hi\", \"<|assistant|>\", \" Hello\", ...]\n",
    "    return parts\n",
    "\n",
    "def merge_consecutive_user(parts):\n",
    "    # Merge adjacent <|user|> contents into a single user payload\n",
    "    merged = []\n",
    "    i = 0\n",
    "    while i < len(parts):\n",
    "        seg = parts[i]\n",
    "        if seg == \"<|user|>\":\n",
    "            payloads = []\n",
    "            j = i + 1\n",
    "            while j < len(parts) and parts[j] not in (\"<|user\\|>\", \"<|assistant|>\"):\n",
    "                payloads.append(parts[j].lstrip(\"\\n\"))\n",
    "                j += 1\n",
    "            # If another <|user|> immediately follows, continue merging\n",
    "            while j < len(parts) and parts[j] == \"<|user|>\":\n",
    "                j += 1\n",
    "                if j < len(parts) and parts[j] not in (\"<|user|>\", \"<|assistant|>\"):\n",
    "                    payloads.append(parts[j].lstrip(\"\\n\"))\n",
    "                    j += 1\n",
    "            merged.extend([\"<|user|>\", (\"\\n\".join(p.strip() for p in payloads)).strip() + \"\\n\"])\n",
    "            i = j\n",
    "        else:\n",
    "            merged.append(seg)\n",
    "            i += 1\n",
    "    return merged\n",
    "\n",
    "def ensure_eos_for_assistant(parts):\n",
    "    fixed = 0\n",
    "    out = []\n",
    "    i = 0\n",
    "    while i < len(parts):\n",
    "        seg = parts[i]\n",
    "        out.append(seg)\n",
    "        if seg == \"<|assistant|>\":\n",
    "            # assistant content is next chunk (may be empty)\n",
    "            content = parts[i+1] if i+1 < len(parts) else \"\"\n",
    "            c = content.rstrip(\"\\n\")\n",
    "            if not c.endswith(EOS):\n",
    "                c = (c + \" \" + EOS).strip()\n",
    "                fixed += 1\n",
    "            out.append(c + \"\\n\")\n",
    "            i += 2\n",
    "        else:\n",
    "            i += 1\n",
    "    return \"\".join(out), fixed\n",
    "\n",
    "fixed_total = 0\n",
    "asst_total = 0\n",
    "\n",
    "with open(OUT, \"w\", encoding=\"utf-8\") as fout, open(IN, \"r\", encoding=\"utf-8\") as fin:\n",
    "    for line in fin:\n",
    "        ex = json.loads(line)\n",
    "        txt = ex.get(\"text\", \"\")\n",
    "        parts = split_turns(txt)\n",
    "        # Optional: merge consecutive user turns (comment out if you want to keep them)\n",
    "        parts = merge_consecutive_user(parts)\n",
    "        # Count assistant turns\n",
    "        asst_total += sum(1 for p in parts if p == \"<|assistant|>\")\n",
    "        new_text, fixed = ensure_eos_for_assistant(parts)\n",
    "        ex[\"text\"] = new_text\n",
    "        fixed_total += fixed\n",
    "        fout.write(json.dumps(ex, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Assistant turns found: {asst_total}\")\n",
    "print(f\"Assistant turns with EOS appended: {fixed_total}\")\n",
    "print(f\"EOS used: {EOS}\")\n",
    "print(f\"Wrote: {OUT}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
