/Users/aryanjain/miniconda3/envs/mindmatenv/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
Loading pretrained model
Loading datasets
Training
Trainable parameters: 0.135% (4.342M/3212.750M)
Starting training..., iters: 1500
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:02<00:49,  2.07s/it]Calculating loss...:   8%|▊         | 2/25 [00:04<00:46,  2.00s/it]Calculating loss...:  12%|█▏        | 3/25 [00:05<00:36,  1.66s/it]Calculating loss...:  16%|█▌        | 4/25 [00:06<00:27,  1.33s/it]Calculating loss...:  20%|██        | 5/25 [00:07<00:28,  1.40s/it]Calculating loss...:  24%|██▍       | 6/25 [00:08<00:25,  1.35s/it]Calculating loss...:  28%|██▊       | 7/25 [00:10<00:22,  1.28s/it]Calculating loss...:  32%|███▏      | 8/25 [00:10<00:19,  1.14s/it]Calculating loss...:  36%|███▌      | 9/25 [00:12<00:22,  1.40s/it]Calculating loss...:  40%|████      | 10/25 [00:14<00:23,  1.54s/it]Calculating loss...:  44%|████▍     | 11/25 [00:15<00:19,  1.41s/it]Calculating loss...:  48%|████▊     | 12/25 [00:17<00:20,  1.59s/it]Calculating loss...:  52%|█████▏    | 13/25 [00:20<00:23,  1.95s/it]Calculating loss...:  56%|█████▌    | 14/25 [00:22<00:20,  1.84s/it]Calculating loss...:  60%|██████    | 15/25 [00:24<00:18,  1.85s/it]Calculating loss...:  64%|██████▍   | 16/25 [00:25<00:16,  1.82s/it]Calculating loss...:  68%|██████▊   | 17/25 [00:28<00:15,  1.97s/it]Calculating loss...:  72%|███████▏  | 18/25 [00:29<00:12,  1.85s/it]Calculating loss...:  76%|███████▌  | 19/25 [00:32<00:12,  2.16s/it]Calculating loss...:  80%|████████  | 20/25 [00:34<00:10,  2.02s/it]Calculating loss...:  84%|████████▍ | 21/25 [00:36<00:08,  2.10s/it]Calculating loss...:  88%|████████▊ | 22/25 [00:37<00:05,  1.89s/it]Calculating loss...:  92%|█████████▏| 23/25 [00:39<00:03,  1.79s/it]Calculating loss...:  96%|█████████▌| 24/25 [00:41<00:01,  1.76s/it]Calculating loss...: 100%|██████████| 25/25 [00:43<00:00,  1.87s/it]Calculating loss...: 100%|██████████| 25/25 [00:43<00:00,  1.73s/it]
Iter 1: Val loss 2.510, Val took 43.331s
Iter 50: Train loss 2.183, Learning Rate 3.000e-05, It/sec 0.369, Tokens/sec 228.873, Trained Tokens 30995, Peak mem 8.222 GB
Iter 100: Train loss 2.136, Learning Rate 3.000e-05, It/sec 0.273, Tokens/sec 201.313, Trained Tokens 67819, Peak mem 10.688 GB
Iter 150: Train loss 2.134, Learning Rate 3.000e-05, It/sec 0.280, Tokens/sec 194.642, Trained Tokens 102622, Peak mem 10.688 GB
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:02<01:09,  2.90s/it]Calculating loss...:   8%|▊         | 2/25 [00:04<00:54,  2.36s/it]Calculating loss...:  12%|█▏        | 3/25 [00:06<00:43,  2.00s/it]Calculating loss...:  16%|█▌        | 4/25 [00:08<00:43,  2.06s/it]Calculating loss...:  20%|██        | 5/25 [00:10<00:41,  2.08s/it]Calculating loss...:  24%|██▍       | 6/25 [00:13<00:45,  2.41s/it]Calculating loss...:  28%|██▊       | 7/25 [00:16<00:44,  2.48s/it]Calculating loss...:  32%|███▏      | 8/25 [00:18<00:41,  2.43s/it]Calculating loss...:  36%|███▌      | 9/25 [00:20<00:36,  2.28s/it]Calculating loss...:  40%|████      | 10/25 [00:22<00:32,  2.18s/it]Calculating loss...:  44%|████▍     | 11/25 [00:23<00:26,  1.92s/it]Calculating loss...:  48%|████▊     | 12/25 [00:25<00:24,  1.88s/it]Calculating loss...:  52%|█████▏    | 13/25 [00:27<00:23,  1.97s/it]Calculating loss...:  56%|█████▌    | 14/25 [00:30<00:23,  2.11s/it]Calculating loss...:  60%|██████    | 15/25 [00:34<00:26,  2.62s/it]Calculating loss...:  64%|██████▍   | 16/25 [00:36<00:21,  2.42s/it]Calculating loss...:  68%|██████▊   | 17/25 [00:37<00:16,  2.06s/it]Calculating loss...:  72%|███████▏  | 18/25 [00:39<00:14,  2.13s/it]Calculating loss...:  76%|███████▌  | 19/25 [00:41<00:12,  2.08s/it]Calculating loss...:  80%|████████  | 20/25 [00:43<00:10,  2.15s/it]Calculating loss...:  84%|████████▍ | 21/25 [00:45<00:07,  1.92s/it]Calculating loss...:  88%|████████▊ | 22/25 [00:46<00:05,  1.82s/it]Calculating loss...:  92%|█████████▏| 23/25 [00:48<00:03,  1.80s/it]Calculating loss...:  96%|█████████▌| 24/25 [00:50<00:01,  1.75s/it]Calculating loss...: 100%|██████████| 25/25 [00:51<00:00,  1.54s/it]Calculating loss...: 100%|██████████| 25/25 [00:51<00:00,  2.05s/it]
Iter 200: Val loss 2.025, Val took 51.358s
Iter 200: Train loss 2.033, Learning Rate 3.000e-05, It/sec 0.295, Tokens/sec 191.256, Trained Tokens 135043, Peak mem 10.688 GB
Iter 200: Saved adapter weights to /Users/aryanjain/projects/mindmate/adapters/mindmate_llama32_3b_qlora_nl10_3072_lr3e5/adapters.safetensors and /Users/aryanjain/projects/mindmate/adapters/mindmate_llama32_3b_qlora_nl10_3072_lr3e5/0000200_adapters.safetensors.
Iter 250: Train loss 2.085, Learning Rate 3.000e-05, It/sec 0.265, Tokens/sec 186.004, Trained Tokens 170119, Peak mem 10.688 GB
Iter 300: Train loss 2.022, Learning Rate 3.000e-05, It/sec 0.286, Tokens/sec 185.103, Trained Tokens 202453, Peak mem 10.688 GB
Iter 350: Train loss 2.020, Learning Rate 3.000e-05, It/sec 0.264, Tokens/sec 182.086, Trained Tokens 236968, Peak mem 10.688 GB
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:01<00:42,  1.77s/it]Calculating loss...:   8%|▊         | 2/25 [00:05<01:08,  2.96s/it]Calculating loss...:  12%|█▏        | 3/25 [00:07<00:56,  2.58s/it]Calculating loss...:  16%|█▌        | 4/25 [00:09<00:47,  2.25s/it]Calculating loss...:  20%|██        | 5/25 [00:10<00:37,  1.87s/it]Calculating loss...:  24%|██▍       | 6/25 [00:12<00:33,  1.77s/it]Calculating loss...:  28%|██▊       | 7/25 [00:13<00:29,  1.65s/it]Calculating loss...:  32%|███▏      | 8/25 [00:15<00:27,  1.63s/it]Calculating loss...:  36%|███▌      | 9/25 [00:16<00:23,  1.50s/it]Calculating loss...:  40%|████      | 10/25 [00:18<00:24,  1.63s/it]Calculating loss...:  44%|████▍     | 11/25 [00:20<00:23,  1.67s/it]Calculating loss...:  48%|████▊     | 12/25 [00:23<00:27,  2.13s/it]Calculating loss...:  52%|█████▏    | 13/25 [00:25<00:24,  2.07s/it]Calculating loss...:  56%|█████▌    | 14/25 [00:26<00:20,  1.87s/it]Calculating loss...:  60%|██████    | 15/25 [00:29<00:22,  2.26s/it]Calculating loss...:  64%|██████▍   | 16/25 [00:31<00:18,  2.06s/it]Calculating loss...:  68%|██████▊   | 17/25 [00:34<00:18,  2.37s/it]Calculating loss...:  72%|███████▏  | 18/25 [00:36<00:14,  2.13s/it]Calculating loss...:  76%|███████▌  | 19/25 [00:37<00:11,  1.96s/it]Calculating loss...:  80%|████████  | 20/25 [00:39<00:09,  1.84s/it]Calculating loss...:  84%|████████▍ | 21/25 [00:42<00:08,  2.20s/it]Calculating loss...:  88%|████████▊ | 22/25 [00:45<00:07,  2.46s/it]Calculating loss...:  92%|█████████▏| 23/25 [00:48<00:05,  2.71s/it]Calculating loss...:  96%|█████████▌| 24/25 [00:51<00:02,  2.92s/it]Calculating loss...: 100%|██████████| 25/25 [00:54<00:00,  2.78s/it]Calculating loss...: 100%|██████████| 25/25 [00:54<00:00,  2.18s/it]
Iter 400: Val loss 2.074, Val took 54.468s
Iter 400: Train loss 2.044, Learning Rate 3.000e-05, It/sec 0.257, Tokens/sec 188.765, Trained Tokens 273662, Peak mem 10.688 GB
Iter 400: Saved adapter weights to /Users/aryanjain/projects/mindmate/adapters/mindmate_llama32_3b_qlora_nl10_3072_lr3e5/adapters.safetensors and /Users/aryanjain/projects/mindmate/adapters/mindmate_llama32_3b_qlora_nl10_3072_lr3e5/0000400_adapters.safetensors.
Iter 450: Train loss 2.060, Learning Rate 3.000e-05, It/sec 0.245, Tokens/sec 186.601, Trained Tokens 311765, Peak mem 10.688 GB
Iter 500: Train loss 2.057, Learning Rate 3.000e-05, It/sec 0.269, Tokens/sec 187.618, Trained Tokens 346627, Peak mem 10.688 GB
Iter 550: Train loss 2.029, Learning Rate 3.000e-05, It/sec 0.268, Tokens/sec 185.382, Trained Tokens 381163, Peak mem 10.688 GB
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:02<01:11,  2.99s/it]Calculating loss...:   8%|▊         | 2/25 [00:04<00:48,  2.13s/it]Calculating loss...:  12%|█▏        | 3/25 [00:06<00:43,  1.99s/it]Calculating loss...:  16%|█▌        | 4/25 [00:07<00:36,  1.72s/it]Calculating loss...:  20%|██        | 5/25 [00:11<00:48,  2.45s/it]Calculating loss...:  24%|██▍       | 6/25 [00:13<00:43,  2.28s/it]Calculating loss...:  28%|██▊       | 7/25 [00:14<00:37,  2.07s/it]Calculating loss...:  32%|███▏      | 8/25 [00:17<00:36,  2.16s/it]Calculating loss...:  36%|███▌      | 9/25 [00:19<00:35,  2.21s/it]Calculating loss...:  40%|████      | 10/25 [00:20<00:28,  1.91s/it]Calculating loss...:  44%|████▍     | 11/25 [00:23<00:29,  2.12s/it]Calculating loss...:  48%|████▊     | 12/25 [00:25<00:28,  2.17s/it]Calculating loss...:  52%|█████▏    | 13/25 [00:28<00:28,  2.34s/it]Calculating loss...:  56%|█████▌    | 14/25 [00:31<00:28,  2.61s/it]Calculating loss...:  60%|██████    | 15/25 [00:33<00:23,  2.31s/it]Calculating loss...:  64%|██████▍   | 16/25 [00:34<00:18,  2.09s/it]Calculating loss...:  68%|██████▊   | 17/25 [00:36<00:15,  1.89s/it]Calculating loss...:  72%|███████▏  | 18/25 [00:37<00:12,  1.80s/it]Calculating loss...:  76%|███████▌  | 19/25 [00:39<00:10,  1.68s/it]Calculating loss...:  80%|████████  | 20/25 [00:40<00:08,  1.67s/it]Calculating loss...:  84%|████████▍ | 21/25 [00:43<00:08,  2.04s/it]Calculating loss...:  88%|████████▊ | 22/25 [00:47<00:07,  2.39s/it]Calculating loss...:  92%|█████████▏| 23/25 [00:49<00:04,  2.34s/it]Calculating loss...:  96%|█████████▌| 24/25 [00:50<00:01,  1.95s/it]Calculating loss...: 100%|██████████| 25/25 [00:51<00:00,  1.79s/it]Calculating loss...: 100%|██████████| 25/25 [00:51<00:00,  2.07s/it]
Iter 600: Val loss 2.050, Val took 51.802s
Iter 600: Train loss 2.072, Learning Rate 3.000e-05, It/sec 0.287, Tokens/sec 185.295, Trained Tokens 413400, Peak mem 10.688 GB
Iter 600: Saved adapter weights to /Users/aryanjain/projects/mindmate/adapters/mindmate_llama32_3b_qlora_nl10_3072_lr3e5/adapters.safetensors and /Users/aryanjain/projects/mindmate/adapters/mindmate_llama32_3b_qlora_nl10_3072_lr3e5/0000600_adapters.safetensors.
Iter 650: Train loss 2.015, Learning Rate 3.000e-05, It/sec 0.287, Tokens/sec 185.441, Trained Tokens 445679, Peak mem 10.688 GB
Iter 700: Train loss 1.910, Learning Rate 3.000e-05, It/sec 0.240, Tokens/sec 182.425, Trained Tokens 483701, Peak mem 10.688 GB
Iter 750: Train loss 1.898, Learning Rate 3.000e-05, It/sec 0.267, Tokens/sec 184.140, Trained Tokens 518145, Peak mem 10.688 GB
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:01<00:39,  1.64s/it]Calculating loss...:   8%|▊         | 2/25 [00:03<00:42,  1.84s/it]Calculating loss...:  12%|█▏        | 3/25 [00:06<00:47,  2.17s/it]Calculating loss...:  16%|█▌        | 4/25 [00:07<00:39,  1.89s/it]Calculating loss...:  20%|██        | 5/25 [00:09<00:34,  1.72s/it]Calculating loss...:  24%|██▍       | 6/25 [00:10<00:28,  1.50s/it]Calculating loss...:  28%|██▊       | 7/25 [00:12<00:29,  1.66s/it]Calculating loss...:  32%|███▏      | 8/25 [00:13<00:26,  1.53s/it]Calculating loss...:  36%|███▌      | 9/25 [00:15<00:28,  1.78s/it]Calculating loss...:  40%|████      | 10/25 [00:18<00:29,  1.98s/it]Calculating loss...:  44%|████▍     | 11/25 [00:19<00:26,  1.92s/it]Calculating loss...:  48%|████▊     | 12/25 [00:21<00:25,  1.93s/it]Calculating loss...:  52%|█████▏    | 13/25 [00:24<00:25,  2.11s/it]Calculating loss...:  56%|█████▌    | 14/25 [00:26<00:21,  1.96s/it]Calculating loss...:  60%|██████    | 15/25 [00:27<00:17,  1.75s/it]Calculating loss...:  64%|██████▍   | 16/25 [00:28<00:14,  1.60s/it]Calculating loss...:  68%|██████▊   | 17/25 [00:30<00:12,  1.61s/it]Calculating loss...:  72%|███████▏  | 18/25 [00:32<00:13,  1.89s/it]Calculating loss...:  76%|███████▌  | 19/25 [00:35<00:12,  2.13s/it]Calculating loss...:  80%|████████  | 20/25 [00:36<00:09,  1.85s/it]Calculating loss...:  84%|████████▍ | 21/25 [00:40<00:09,  2.34s/it]Calculating loss...:  88%|████████▊ | 22/25 [00:41<00:06,  2.06s/it]Calculating loss...:  92%|█████████▏| 23/25 [00:43<00:04,  2.08s/it]Calculating loss...:  96%|█████████▌| 24/25 [00:45<00:02,  2.10s/it]Calculating loss...: 100%|██████████| 25/25 [00:47<00:00,  2.03s/it]Calculating loss...: 100%|██████████| 25/25 [00:47<00:00,  1.90s/it]
Iter 800: Val loss 2.053, Val took 47.654s
Iter 800: Train loss 1.926, Learning Rate 3.000e-05, It/sec 0.270, Tokens/sec 183.275, Trained Tokens 552114, Peak mem 10.688 GB
Iter 800: Saved adapter weights to /Users/aryanjain/projects/mindmate/adapters/mindmate_llama32_3b_qlora_nl10_3072_lr3e5/adapters.safetensors and /Users/aryanjain/projects/mindmate/adapters/mindmate_llama32_3b_qlora_nl10_3072_lr3e5/0000800_adapters.safetensors.
Iter 850: Train loss 1.983, Learning Rate 3.000e-05, It/sec 0.269, Tokens/sec 183.184, Trained Tokens 586213, Peak mem 10.688 GB
Iter 900: Train loss 1.880, Learning Rate 3.000e-05, It/sec 0.305, Tokens/sec 186.883, Trained Tokens 616864, Peak mem 10.688 GB
Iter 950: Train loss 1.921, Learning Rate 3.000e-05, It/sec 0.238, Tokens/sec 182.514, Trained Tokens 655274, Peak mem 10.688 GB
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:02<00:58,  2.42s/it]Calculating loss...:   8%|▊         | 2/25 [00:07<01:27,  3.78s/it]Calculating loss...:  12%|█▏        | 3/25 [00:08<01:01,  2.81s/it]Calculating loss...:  16%|█▌        | 4/25 [00:10<00:47,  2.26s/it]Calculating loss...:  20%|██        | 5/25 [00:12<00:44,  2.24s/it]Calculating loss...:  24%|██▍       | 6/25 [00:15<00:48,  2.57s/it]Calculating loss...:  28%|██▊       | 7/25 [00:17<00:43,  2.41s/it]Calculating loss...:  32%|███▏      | 8/25 [00:19<00:37,  2.23s/it]Calculating loss...:  36%|███▌      | 9/25 [00:21<00:31,  1.99s/it]Calculating loss...:  40%|████      | 10/25 [00:23<00:32,  2.15s/it]Calculating loss...:  44%|████▍     | 11/25 [00:25<00:30,  2.21s/it]Calculating loss...:  48%|████▊     | 12/25 [00:27<00:25,  1.98s/it]Calculating loss...:  52%|█████▏    | 13/25 [00:29<00:24,  2.03s/it]Calculating loss...:  56%|█████▌    | 14/25 [00:31<00:22,  2.02s/it]Calculating loss...:  60%|██████    | 15/25 [00:33<00:19,  1.90s/it]Calculating loss...:  64%|██████▍   | 16/25 [00:35<00:17,  1.98s/it]Calculating loss...:  68%|██████▊   | 17/25 [00:36<00:14,  1.81s/it]Calculating loss...:  72%|███████▏  | 18/25 [00:38<00:11,  1.69s/it]Calculating loss...:  76%|███████▌  | 19/25 [00:39<00:10,  1.68s/it]Calculating loss...:  80%|████████  | 20/25 [00:43<00:11,  2.34s/it]Calculating loss...:  84%|████████▍ | 21/25 [00:45<00:08,  2.18s/it]Calculating loss...:  88%|████████▊ | 22/25 [00:48<00:07,  2.36s/it]Calculating loss...:  92%|█████████▏| 23/25 [00:50<00:04,  2.36s/it]Calculating loss...:  96%|█████████▌| 24/25 [00:52<00:02,  2.09s/it]Calculating loss...: 100%|██████████| 25/25 [00:53<00:00,  2.00s/it]Calculating loss...: 100%|██████████| 25/25 [00:53<00:00,  2.15s/it]
Iter 1000: Val loss 2.027, Val took 53.869s
Iter 1000: Train loss 1.935, Learning Rate 3.000e-05, It/sec 0.242, Tokens/sec 180.383, Trained Tokens 692470, Peak mem 10.705 GB
Iter 1000: Saved adapter weights to /Users/aryanjain/projects/mindmate/adapters/mindmate_llama32_3b_qlora_nl10_3072_lr3e5/adapters.safetensors and /Users/aryanjain/projects/mindmate/adapters/mindmate_llama32_3b_qlora_nl10_3072_lr3e5/0001000_adapters.safetensors.
Iter 1050: Train loss 1.832, Learning Rate 3.000e-05, It/sec 0.277, Tokens/sec 182.804, Trained Tokens 725513, Peak mem 10.705 GB
Iter 1100: Train loss 1.894, Learning Rate 3.000e-05, It/sec 0.271, Tokens/sec 180.235, Trained Tokens 758758, Peak mem 10.705 GB
Iter 1150: Train loss 1.959, Learning Rate 3.000e-05, It/sec 0.264, Tokens/sec 183.310, Trained Tokens 793536, Peak mem 10.705 GB
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:01<00:45,  1.90s/it]Calculating loss...:   8%|▊         | 2/25 [00:03<00:39,  1.74s/it]Calculating loss...:  12%|█▏        | 3/25 [00:05<00:37,  1.69s/it]Calculating loss...:  16%|█▌        | 4/25 [00:08<00:48,  2.30s/it]Calculating loss...:  20%|██        | 5/25 [00:09<00:40,  2.05s/it]Calculating loss...:  24%|██▍       | 6/25 [00:12<00:43,  2.30s/it]Calculating loss...:  28%|██▊       | 7/25 [00:16<00:47,  2.62s/it]Calculating loss...:  32%|███▏      | 8/25 [00:17<00:37,  2.19s/it]Calculating loss...:  36%|███▌      | 9/25 [00:20<00:37,  2.37s/it]Calculating loss...:  40%|████      | 10/25 [00:21<00:33,  2.20s/it]Calculating loss...:  44%|████▍     | 11/25 [00:23<00:29,  2.08s/it]Calculating loss...:  48%|████▊     | 12/25 [00:25<00:23,  1.83s/it]Calculating loss...:  52%|█████▏    | 13/25 [00:27<00:23,  1.96s/it]Calculating loss...:  56%|█████▌    | 14/25 [00:29<00:20,  1.91s/it]Calculating loss...:  60%|██████    | 15/25 [00:32<00:23,  2.34s/it]Calculating loss...:  64%|██████▍   | 16/25 [00:33<00:17,  1.96s/it]Calculating loss...:  68%|██████▊   | 17/25 [00:35<00:14,  1.85s/it]Calculating loss...:  72%|███████▏  | 18/25 [00:36<00:12,  1.79s/it]Calculating loss...:  76%|███████▌  | 19/25 [00:38<00:11,  1.91s/it]Calculating loss...:  80%|████████  | 20/25 [00:41<00:10,  2.05s/it]Calculating loss...:  84%|████████▍ | 21/25 [00:42<00:07,  1.81s/it]Calculating loss...:  88%|████████▊ | 22/25 [00:44<00:05,  1.98s/it]Calculating loss...:  92%|█████████▏| 23/25 [00:47<00:04,  2.04s/it]Calculating loss...:  96%|█████████▌| 24/25 [00:49<00:02,  2.02s/it]Calculating loss...: 100%|██████████| 25/25 [00:51<00:00,  2.07s/it]Calculating loss...: 100%|██████████| 25/25 [00:51<00:00,  2.05s/it]
Iter 1200: Val loss 2.106, Val took 51.285s
Iter 1200: Train loss 1.915, Learning Rate 3.000e-05, It/sec 0.279, Tokens/sec 184.811, Trained Tokens 826649, Peak mem 10.705 GB
Iter 1200: Saved adapter weights to /Users/aryanjain/projects/mindmate/adapters/mindmate_llama32_3b_qlora_nl10_3072_lr3e5/adapters.safetensors and /Users/aryanjain/projects/mindmate/adapters/mindmate_llama32_3b_qlora_nl10_3072_lr3e5/0001200_adapters.safetensors.
Iter 1250: Train loss 1.904, Learning Rate 3.000e-05, It/sec 0.279, Tokens/sec 182.339, Trained Tokens 859311, Peak mem 10.705 GB
Iter 1300: Train loss 1.909, Learning Rate 3.000e-05, It/sec 0.249, Tokens/sec 182.824, Trained Tokens 896051, Peak mem 10.705 GB
Iter 1350: Train loss 1.821, Learning Rate 3.000e-05, It/sec 0.256, Tokens/sec 182.275, Trained Tokens 931598, Peak mem 10.705 GB
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:02<01:03,  2.64s/it]Calculating loss...:   8%|▊         | 2/25 [00:04<00:44,  1.94s/it]Calculating loss...:  12%|█▏        | 3/25 [00:05<00:37,  1.71s/it]Calculating loss...:  16%|█▌        | 4/25 [00:06<00:32,  1.54s/it]Calculating loss...:  20%|██        | 5/25 [00:08<00:28,  1.44s/it]Calculating loss...:  24%|██▍       | 6/25 [00:09<00:28,  1.50s/it]Calculating loss...:  28%|██▊       | 7/25 [00:10<00:24,  1.36s/it]Calculating loss...:  32%|███▏      | 8/25 [00:12<00:25,  1.51s/it]Calculating loss...:  36%|███▌      | 9/25 [00:14<00:25,  1.60s/it]Calculating loss...:  40%|████      | 10/25 [00:16<00:24,  1.67s/it]Calculating loss...:  44%|████▍     | 11/25 [00:18<00:25,  1.83s/it]Calculating loss...:  48%|████▊     | 12/25 [00:20<00:23,  1.82s/it]Calculating loss...:  52%|█████▏    | 13/25 [00:22<00:21,  1.82s/it]Calculating loss...:  56%|█████▌    | 14/25 [00:24<00:23,  2.15s/it]Calculating loss...:  60%|██████    | 15/25 [00:26<00:20,  2.05s/it]Calculating loss...:  64%|██████▍   | 16/25 [00:30<00:21,  2.42s/it]Calculating loss...:  68%|██████▊   | 17/25 [00:31<00:17,  2.18s/it]Calculating loss...:  72%|███████▏  | 18/25 [00:34<00:16,  2.29s/it]Calculating loss...:  76%|███████▌  | 19/25 [00:36<00:14,  2.43s/it]Calculating loss...:  80%|████████  | 20/25 [00:40<00:13,  2.70s/it]Calculating loss...:  84%|████████▍ | 21/25 [00:42<00:09,  2.49s/it]Calculating loss...:  88%|████████▊ | 22/25 [00:45<00:08,  2.78s/it]Calculating loss...:  92%|█████████▏| 23/25 [00:47<00:04,  2.44s/it]Calculating loss...:  96%|█████████▌| 24/25 [00:48<00:02,  2.09s/it]Calculating loss...: 100%|██████████| 25/25 [00:51<00:00,  2.22s/it]Calculating loss...: 100%|██████████| 25/25 [00:51<00:00,  2.05s/it]
Iter 1400: Val loss 2.089, Val took 51.242s
Iter 1400: Train loss 1.725, Learning Rate 3.000e-05, It/sec 0.297, Tokens/sec 182.886, Trained Tokens 962432, Peak mem 10.705 GB
Iter 1400: Saved adapter weights to /Users/aryanjain/projects/mindmate/adapters/mindmate_llama32_3b_qlora_nl10_3072_lr3e5/adapters.safetensors and /Users/aryanjain/projects/mindmate/adapters/mindmate_llama32_3b_qlora_nl10_3072_lr3e5/0001400_adapters.safetensors.
Iter 1450: Train loss 1.722, Learning Rate 3.000e-05, It/sec 0.261, Tokens/sec 179.185, Trained Tokens 996714, Peak mem 10.705 GB
Calculating loss...:   0%|          | 0/25 [00:00<?, ?it/s]Calculating loss...:   4%|▍         | 1/25 [00:01<00:40,  1.70s/it]Calculating loss...:   8%|▊         | 2/25 [00:05<01:01,  2.65s/it]Calculating loss...:  12%|█▏        | 3/25 [00:06<00:46,  2.10s/it]Calculating loss...:  16%|█▌        | 4/25 [00:08<00:40,  1.92s/it]Calculating loss...:  20%|██        | 5/25 [00:09<00:36,  1.80s/it]Calculating loss...:  24%|██▍       | 6/25 [00:11<00:31,  1.68s/it]Calculating loss...:  28%|██▊       | 7/25 [00:12<00:29,  1.66s/it]Calculating loss...:  32%|███▏      | 8/25 [00:14<00:30,  1.82s/it]Calculating loss...:  36%|███▌      | 9/25 [00:16<00:26,  1.64s/it]Calculating loss...:  40%|████      | 10/25 [00:18<00:28,  1.88s/it]Calculating loss...:  44%|████▍     | 11/25 [00:19<00:23,  1.69s/it]Calculating loss...:  48%|████▊     | 12/25 [00:21<00:23,  1.78s/it]Calculating loss...:  52%|█████▏    | 13/25 [00:23<00:22,  1.84s/it]Calculating loss...:  56%|█████▌    | 14/25 [00:27<00:25,  2.28s/it]Calculating loss...:  60%|██████    | 15/25 [00:28<00:20,  2.08s/it]Calculating loss...:  64%|██████▍   | 16/25 [00:31<00:19,  2.19s/it]Calculating loss...:  68%|██████▊   | 17/25 [00:33<00:18,  2.35s/it]Calculating loss...:  72%|███████▏  | 18/25 [00:35<00:15,  2.25s/it]Calculating loss...:  76%|███████▌  | 19/25 [00:39<00:15,  2.61s/it]Calculating loss...:  80%|████████  | 20/25 [00:41<00:12,  2.43s/it]Calculating loss...:  84%|████████▍ | 21/25 [00:43<00:08,  2.24s/it]Calculating loss...:  88%|████████▊ | 22/25 [00:45<00:07,  2.33s/it]Calculating loss...:  92%|█████████▏| 23/25 [00:47<00:04,  2.30s/it]Calculating loss...:  96%|█████████▌| 24/25 [00:49<00:02,  2.21s/it]Calculating loss...: 100%|██████████| 25/25 [00:53<00:00,  2.53s/it]Calculating loss...: 100%|██████████| 25/25 [00:53<00:00,  2.13s/it]
Iter 1500: Val loss 2.091, Val took 53.249s
Iter 1500: Train loss 1.767, Learning Rate 3.000e-05, It/sec 0.282, Tokens/sec 183.160, Trained Tokens 1029146, Peak mem 10.705 GB
Saved final weights to /Users/aryanjain/projects/mindmate/adapters/mindmate_llama32_3b_qlora_nl10_3072_lr3e5/adapters.safetensors.
